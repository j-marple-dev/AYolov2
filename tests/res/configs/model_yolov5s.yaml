input_size: [256, 256]
input_channel: 3

depth_multiple: 0.33
width_multiple: 0.5

anchors: &anchors
   - [10,13, 16,30, 33,23]  # P3/8
   - [30,61, 62,45, 59,119]  # P4
   - [116,90, 156,198, 373,326]  # P5/32

n_classes: &n_classes
  80

activation: &activation
  SiLU

backbone:
    # [from, repeat, module, args]
    [
        [-1, 1, Focus, [64, 3], {activation: *activation}],
        [-1, 1, Conv, [128, 3, 2], {activation: *activation}],
        [-1, 3, C3, [128], {activation: *activation}],  # 2

        [-1, 1, Conv, [256, 3, 2], {activation: *activation}],
        [-1, 9, C3, [256], {activation: *activation}],  # 4

        [-1, 1, Conv, [512, 3, 2], {activation: *activation}],
        [-1, 9, C3, [512], {activation: *activation}],  # 6

        [-1, 1, Conv, [1024, 3, 2], {activation: *activation}],
        [-1, 1, SPP, [1024, [5, 9, 13]], {activation: *activation}],
        [-1, 3, C3, [1024, False], {activation: *activation}],  # 9

        [-1, 1, Conv, [512, 1, 1], {activation: *activation}],
        [-1, 1, UpSample, [null, 2]],
        [[-1, 6], 1, Concat, [1]],
        [-1, 3, C3, [512, False], {activation: *activation}],  # 13

        [-1, 1, Conv, [256, 1, 1], {activation: *activation}],
        [-1, 1, UpSample, [null, 2]],
        [[-1, 4], 1, Concat, [1]], 
        [-1, 1, C3, [256, False], {activation: *activation}],  # 17

        [-1, 1, Conv, [256, 3, 2], {activation: *activation}],
        [[-1, 14], 1, Concat, [1]],
        [-1, 3, C3, [512, False], {activation: *activation}],  # 20
        
        [-1, 1, Conv, [512, 3, 2], {activation: *activation}],
        [[-1, 10], 1, Concat, [1]],
        [-1, 3, C3, [1024, False], {activation: *activation}]  # 23
    ]

head:
  [
    [[17, 20, 23], 1, YOLOHead, [*n_classes, *anchors]]
  ]

